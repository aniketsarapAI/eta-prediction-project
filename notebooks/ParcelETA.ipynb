{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUSKowEBPZi6",
        "outputId": "2fbe968a-ddee-4a5b-b716-7fd5e1608576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully!\n",
            "üìä Pandas version: 2.2.2\n",
            "üî¢ Numpy version: 2.0.2\n"
          ]
        }
      ],
      "source": [
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"üìä Pandas version: {pd.__version__}\")\n",
        "print(f\"üî¢ Numpy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V69wMSrXPnx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10981442",
        "outputId": "54992966-c1ed-45ca-f2dc-7d5fa86a1107"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the zip file\n",
        "zip_path = '/content/archive (1).zip'\n",
        "# Define the directory to extract the files to\n",
        "extracted_path = '/content/extracted_data'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "if not os.path.exists(extracted_path):\n",
        "    os.makedirs(extracted_path)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "print(f\"‚úÖ Files extracted to: {extracted_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Files extracted to: /content/extracted_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what's in the extracted directory\n",
        "import os\n",
        "\n",
        "extracted_path = '/content/extracted_data'\n",
        "print(\"üìÇ Contents of extracted directory:\")\n",
        "for item in os.listdir(extracted_path):\n",
        "    item_path = os.path.join(extracted_path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        print(f\"üìÅ Directory: {item}/\")\n",
        "        # If it's a directory, show its contents too\n",
        "        for subitem in os.listdir(item_path):\n",
        "            print(f\"   üìÑ {subitem}\")\n",
        "    else:\n",
        "        print(f\"üìÑ File: {item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEVayZFjP9VB",
        "outputId": "8544e95a-1f0f-440f-ee63-c7bfeaefd0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Contents of extracted directory:\n",
            "üìÑ File: product_category_name_translation.csv\n",
            "üìÑ File: olist_customers_dataset.csv\n",
            "üìÑ File: olist_order_payments_dataset.csv\n",
            "üìÑ File: olist_order_items_dataset.csv\n",
            "üìÑ File: olist_products_dataset.csv\n",
            "üìÑ File: olist_orders_dataset.csv\n",
            "üìÑ File: olist_geolocation_dataset.csv\n",
            "üìÑ File: olist_order_reviews_dataset.csv\n",
            "üìÑ File: olist_sellers_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import essential libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "\n",
        "# Define correct data path\n",
        "data_path = '/content/extracted_data/'\n",
        "\n",
        "# Load all CSV files\n",
        "files = {\n",
        "    'orders': 'olist_orders_dataset.csv',\n",
        "    'order_items': 'olist_order_items_dataset.csv',\n",
        "    'products': 'olist_products_dataset.csv',\n",
        "    'customers': 'olist_customers_dataset.csv',\n",
        "    'sellers': 'olist_sellers_dataset.csv',\n",
        "    'payments': 'olist_order_payments_dataset.csv',\n",
        "    'reviews': 'olist_order_reviews_dataset.csv',\n",
        "    'geolocation': 'olist_geolocation_dataset.csv',\n",
        "    'category_translation': 'product_category_name_translation.csv'\n",
        "}\n",
        "\n",
        "# Load datasets\n",
        "datasets = {}\n",
        "for name, filename in files.items():\n",
        "    datasets[name] = pd.read_csv(data_path + filename)\n",
        "    print(f\"‚úÖ Loaded {name}: {datasets[name].shape}\")\n",
        "\n",
        "print(f\"\\nüéØ Total datasets loaded: {len(datasets)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZunw1JuP97X",
        "outputId": "9c13656c-0b46-4762-8783-b42644e23ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully!\n",
            "‚úÖ Loaded orders: (99441, 8)\n",
            "‚úÖ Loaded order_items: (112650, 7)\n",
            "‚úÖ Loaded products: (32951, 9)\n",
            "‚úÖ Loaded customers: (99441, 5)\n",
            "‚úÖ Loaded sellers: (3095, 4)\n",
            "‚úÖ Loaded payments: (103886, 5)\n",
            "‚úÖ Loaded reviews: (99224, 7)\n",
            "‚úÖ Loaded geolocation: (1000163, 5)\n",
            "‚úÖ Loaded category_translation: (71, 2)\n",
            "\n",
            "üéØ Total datasets loaded: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick inspection of key datasets\n",
        "print(\"üìã ORDERS DATASET:\")\n",
        "print(datasets['orders'].head(3))\n",
        "print(f\"Columns: {list(datasets['orders'].columns)}\")\n",
        "print(f\"Date range: {datasets['orders']['order_purchase_timestamp'].min()} to {datasets['orders']['order_purchase_timestamp'].max()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìã ORDER ITEMS DATASET:\")\n",
        "print(datasets['order_items'].head(3))\n",
        "print(f\"Columns: {list(datasets['order_items'].columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlxXCo_FQGHx",
        "outputId": "6be6715f-81df-4443-8252-3efefdf8288a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã ORDERS DATASET:\n",
            "                           order_id                       customer_id order_status order_purchase_timestamp    order_approved_at order_delivered_carrier_date order_delivered_customer_date order_estimated_delivery_date\n",
            "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15          2017-10-04 19:55:00           2017-10-10 21:25:13           2017-10-18 00:00:00\n",
            "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27          2018-07-26 14:31:00           2018-08-07 15:27:45           2018-08-13 00:00:00\n",
            "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23          2018-08-08 13:50:00           2018-08-17 18:06:29           2018-09-04 00:00:00\n",
            "Columns: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
            "Date range: 2016-09-04 21:15:19 to 2018-10-17 17:30:18\n",
            "\n",
            "================================================================================\n",
            "üìã ORDER ITEMS DATASET:\n",
            "                           order_id  order_item_id                        product_id                         seller_id  shipping_limit_date  price  freight_value\n",
            "0  00010242fe8c5a6d1ba2dd792cb16214              1  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202  2017-09-19 09:45:35   58.9          13.29\n",
            "1  00018f77f2f0320c557190d7a144bdd3              1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36  2017-05-03 11:05:13  239.9          19.93\n",
            "2  000229ec398224ef6ca0657da4fc703e              1  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d  2018-01-18 14:48:30  199.0          17.87\n",
            "Columns: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types and missing values for key datasets\n",
        "key_datasets = ['orders', 'order_items', 'customers', 'products']\n",
        "\n",
        "for dataset_name in key_datasets:\n",
        "    print(f\"\\nüìä {dataset_name.upper()} - Data Types & Missing Values:\")\n",
        "    df = datasets[dataset_name]\n",
        "\n",
        "    # Create info summary\n",
        "    info_df = pd.DataFrame({\n",
        "        'Column': df.columns,\n",
        "        'Non-Null Count': df.count(),\n",
        "        'Null Count': df.isnull().sum(),\n",
        "        'Null %': round((df.isnull().sum() / len(df)) * 100, 2),\n",
        "        'Data Type': df.dtypes\n",
        "    })\n",
        "\n",
        "    print(info_df)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy1dwzdeQP6G",
        "outputId": "c0d5dbe0-7282-4854-bf6f-298c023b5abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä ORDERS - Data Types & Missing Values:\n",
            "                                                      Column  Non-Null Count  Null Count  Null % Data Type\n",
            "order_id                                            order_id           99441           0    0.00    object\n",
            "customer_id                                      customer_id           99441           0    0.00    object\n",
            "order_status                                    order_status           99441           0    0.00    object\n",
            "order_purchase_timestamp            order_purchase_timestamp           99441           0    0.00    object\n",
            "order_approved_at                          order_approved_at           99281         160    0.16    object\n",
            "order_delivered_carrier_date    order_delivered_carrier_date           97658        1783    1.79    object\n",
            "order_delivered_customer_date  order_delivered_customer_date           96476        2965    2.98    object\n",
            "order_estimated_delivery_date  order_estimated_delivery_date           99441           0    0.00    object\n",
            "--------------------------------------------------\n",
            "\n",
            "üìä ORDER_ITEMS - Data Types & Missing Values:\n",
            "                                  Column  Non-Null Count  Null Count  Null % Data Type\n",
            "order_id                        order_id          112650           0     0.0    object\n",
            "order_item_id              order_item_id          112650           0     0.0     int64\n",
            "product_id                    product_id          112650           0     0.0    object\n",
            "seller_id                      seller_id          112650           0     0.0    object\n",
            "shipping_limit_date  shipping_limit_date          112650           0     0.0    object\n",
            "price                              price          112650           0     0.0   float64\n",
            "freight_value              freight_value          112650           0     0.0   float64\n",
            "--------------------------------------------------\n",
            "\n",
            "üìä CUSTOMERS - Data Types & Missing Values:\n",
            "                                            Column  Non-Null Count  Null Count  Null % Data Type\n",
            "customer_id                            customer_id           99441           0     0.0    object\n",
            "customer_unique_id              customer_unique_id           99441           0     0.0    object\n",
            "customer_zip_code_prefix  customer_zip_code_prefix           99441           0     0.0     int64\n",
            "customer_city                        customer_city           99441           0     0.0    object\n",
            "customer_state                      customer_state           99441           0     0.0    object\n",
            "--------------------------------------------------\n",
            "\n",
            "üìä PRODUCTS - Data Types & Missing Values:\n",
            "                                                Column  Non-Null Count  Null Count  Null % Data Type\n",
            "product_id                                  product_id           32951           0    0.00    object\n",
            "product_category_name            product_category_name           32341         610    1.85    object\n",
            "product_name_lenght                product_name_lenght           32341         610    1.85   float64\n",
            "product_description_lenght  product_description_lenght           32341         610    1.85   float64\n",
            "product_photos_qty                  product_photos_qty           32341         610    1.85   float64\n",
            "product_weight_g                      product_weight_g           32949           2    0.01   float64\n",
            "product_length_cm                    product_length_cm           32949           2    0.01   float64\n",
            "product_height_cm                    product_height_cm           32949           2    0.01   float64\n",
            "product_width_cm                      product_width_cm           32949           2    0.01   float64\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore relationships between datasets\n",
        "print(\"üîó DATASET RELATIONSHIPS:\")\n",
        "\n",
        "print(f\"Total unique orders: {datasets['orders']['order_id'].nunique()}\")\n",
        "print(f\"Total unique customers: {datasets['customers']['customer_id'].nunique()}\")\n",
        "print(f\"Total unique sellers: {datasets['sellers']['seller_id'].nunique()}\")\n",
        "print(f\"Total unique products: {datasets['products']['product_id'].nunique()}\")\n",
        "\n",
        "print(f\"\\nOrders vs Order Items:\")\n",
        "print(f\"Orders with items: {datasets['order_items']['order_id'].nunique()}\")\n",
        "print(f\"Average items per order: {len(datasets['order_items']) / datasets['order_items']['order_id'].nunique():.2f}\")\n",
        "\n",
        "print(f\"\\nOrders vs Payments:\")\n",
        "print(f\"Orders with payments: {datasets['payments']['order_id'].nunique()}\")\n",
        "\n",
        "print(f\"\\nOrders vs Reviews:\")\n",
        "print(f\"Orders with reviews: {datasets['reviews']['order_id'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWBASXQ4QRd2",
        "outputId": "6ccee18c-3f4a-468b-c386-39ac5816c8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó DATASET RELATIONSHIPS:\n",
            "Total unique orders: 99441\n",
            "Total unique customers: 99441\n",
            "Total unique sellers: 3095\n",
            "Total unique products: 32951\n",
            "\n",
            "Orders vs Order Items:\n",
            "Orders with items: 98666\n",
            "Average items per order: 1.14\n",
            "\n",
            "Orders vs Payments:\n",
            "Orders with payments: 99440\n",
            "\n",
            "Orders vs Reviews:\n",
            "Orders with reviews: 98673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all timestamp columns to datetime\n",
        "date_columns = ['order_purchase_timestamp', 'order_approved_at',\n",
        "                'order_delivered_carrier_date', 'order_delivered_customer_date',\n",
        "                'order_estimated_delivery_date']\n",
        "\n",
        "for col in date_columns:\n",
        "    datasets['orders'][col] = pd.to_datetime(datasets['orders'][col])\n",
        "\n",
        "# Convert shipping limit date in order_items\n",
        "datasets['order_items']['shipping_limit_date'] = pd.to_datetime(datasets['order_items']['shipping_limit_date'])\n",
        "\n",
        "print(\"‚úÖ All date columns converted to datetime\")\n",
        "\n",
        "# Create core delivery features\n",
        "df_orders = datasets['orders'].copy()\n",
        "\n",
        "# Calculate actual delivery time (days from purchase to delivery)\n",
        "delivered_orders = df_orders[df_orders['order_delivered_customer_date'].notna()]\n",
        "delivered_orders['delivery_time_days'] = (\n",
        "    delivered_orders['order_delivered_customer_date'] - delivered_orders['order_purchase_timestamp']\n",
        ").dt.total_seconds() / (24 * 3600)\n",
        "\n",
        "# Calculate if order was delivered late\n",
        "delivered_orders['estimated_delivery_days'] = (\n",
        "    delivered_orders['order_estimated_delivery_date'] - delivered_orders['order_purchase_timestamp']\n",
        ").dt.total_seconds() / (24 * 3600)\n",
        "\n",
        "delivered_orders['is_late'] = delivered_orders['delivery_time_days'] > delivered_orders['estimated_delivery_days']\n",
        "\n",
        "print(f\"\\nüìä DELIVERY ANALYSIS:\")\n",
        "print(f\"Orders with delivery data: {len(delivered_orders)}\")\n",
        "print(f\"Average delivery time: {delivered_orders['delivery_time_days'].mean():.2f} days\")\n",
        "print(f\"Late deliveries: {delivered_orders['is_late'].sum()} ({delivered_orders['is_late'].mean()*100:.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4nl3VcJQVZH",
        "outputId": "9fcdd95e-6e33-4966-8731-9b71ead7d41a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All date columns converted to datetime\n",
            "\n",
            "üìä DELIVERY ANALYSIS:\n",
            "Orders with delivery data: 96476\n",
            "Average delivery time: 12.56 days\n",
            "Late deliveries: 7827 (8.1%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge customers and sellers geography\n",
        "df_with_geo = delivered_orders.merge(\n",
        "    datasets['customers'][['customer_id', 'customer_state', 'customer_zip_code_prefix']],\n",
        "    on='customer_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Get seller info through order_items\n",
        "order_seller = datasets['order_items'].groupby('order_id').agg({\n",
        "    'seller_id': 'first',  # Take first seller for multi-seller orders\n",
        "    'price': 'sum',\n",
        "    'freight_value': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "df_with_geo = df_with_geo.merge(order_seller, on='order_id', how='left')\n",
        "df_with_geo = df_with_geo.merge(\n",
        "    datasets['sellers'][['seller_id', 'seller_state']],\n",
        "    on='seller_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Create same_state feature (key predictor from your analysis)\n",
        "df_with_geo['same_state'] = (df_with_geo['customer_state'] == df_with_geo['seller_state']).astype(int)\n",
        "\n",
        "print(\"‚úÖ Geographic features created\")\n",
        "print(f\"Same state deliveries: {df_with_geo['same_state'].sum()} ({df_with_geo['same_state'].mean()*100:.1f}%)\")\n",
        "\n",
        "# Validate your key finding\n",
        "same_state_avg = df_with_geo[df_with_geo['same_state'] == 1]['delivery_time_days'].mean()\n",
        "diff_state_avg = df_with_geo[df_with_geo['same_state'] == 0]['delivery_time_days'].mean()\n",
        "\n",
        "print(f\"\\nüéØ KEY INSIGHT VALIDATION:\")\n",
        "print(f\"Same state avg delivery: {same_state_avg:.1f} days\")\n",
        "print(f\"Different state avg delivery: {diff_state_avg:.1f} days\")\n",
        "print(f\"Difference: {diff_state_avg - same_state_avg:.1f} days\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8mHdFU4QoHu",
        "outputId": "97dfa56b-288b-490c-f3e2-4ae879114917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Geographic features created\n",
            "Same state deliveries: 34703 (36.0%)\n",
            "\n",
            "üéØ KEY INSIGHT VALIDATION:\n",
            "Same state avg delivery: 7.9 days\n",
            "Different state avg delivery: 15.2 days\n",
            "Difference: 7.2 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add temporal features\n",
        "df_with_geo['purchase_month'] = df_with_geo['order_purchase_timestamp'].dt.month\n",
        "df_with_geo['purchase_dow'] = df_with_geo['order_purchase_timestamp'].dt.dayofweek\n",
        "df_with_geo['purchase_year'] = df_with_geo['order_purchase_timestamp'].dt.year\n",
        "\n",
        "# Order items analysis\n",
        "order_summary = datasets['order_items'].groupby('order_id').agg({\n",
        "    'order_item_id': 'count',  # number of items\n",
        "    'price': ['sum', 'mean'],\n",
        "    'freight_value': ['sum', 'mean']\n",
        "}).round(2)\n",
        "\n",
        "order_summary.columns = ['n_items', 'total_price', 'avg_item_price', 'total_freight', 'avg_freight']\n",
        "order_summary = order_summary.reset_index()\n",
        "\n",
        "# Merge with main dataframe\n",
        "df_final = df_with_geo.merge(order_summary, on='order_id', how='left')\n",
        "\n",
        "print(\"‚úÖ Order value and temporal features added\")\n",
        "print(f\"Final dataset shape: {df_final.shape}\")\n",
        "print(f\"\\nFeature summary:\")\n",
        "for col in ['n_items', 'total_price', 'total_freight', 'delivery_time_days']:\n",
        "    if col in df_final.columns:\n",
        "        print(f\"{col}: mean={df_final[col].mean():.2f}, std={df_final[col].std():.2f}\")\n",
        "\n",
        "# Quick correlation check\n",
        "corr_features = ['delivery_time_days', 'same_state', 'n_items', 'total_price', 'total_freight']\n",
        "print(f\"\\nüîó Correlation with delivery_time_days:\")\n",
        "correlations = df_final[corr_features].corr()['delivery_time_days'].sort_values(key=abs, ascending=False)\n",
        "print(correlations.drop('delivery_time_days'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhwLtkuMQsa4",
        "outputId": "c403492e-947f-4758-83a1-44efe0347b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Order value and temporal features added\n",
            "Final dataset shape: (96476, 26)\n",
            "\n",
            "Feature summary:\n",
            "n_items: mean=1.14, std=0.54\n",
            "total_price: mean=137.04, std=209.05\n",
            "total_freight: mean=22.79, std=21.56\n",
            "delivery_time_days: mean=12.56, std=9.55\n",
            "\n",
            "üîó Correlation with delivery_time_days:\n",
            "same_state      -0.362200\n",
            "total_freight    0.167138\n",
            "total_price      0.055578\n",
            "n_items         -0.019113\n",
            "Name: delivery_time_days, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Customer RFM Analysis (Recency, Frequency, Monetary)\n",
        "print(\"üßÆ BUILDING CUSTOMER RFM SEGMENTATION...\")\n",
        "\n",
        "# Get customer order history\n",
        "customer_analysis = df_final.groupby('customer_id').agg({\n",
        "    'order_purchase_timestamp': ['count', 'max'],  # Frequency, Last order date\n",
        "    'total_price': 'sum',  # Total spent (Monetary)\n",
        "    'delivery_time_days': 'mean'  # Avg delivery experience\n",
        "}).round(2)\n",
        "\n",
        "customer_analysis.columns = ['order_frequency', 'last_order_date', 'total_monetary_value', 'avg_delivery_days']\n",
        "customer_analysis = customer_analysis.reset_index()\n",
        "\n",
        "# Calculate Recency (days since last order)\n",
        "reference_date = df_final['order_purchase_timestamp'].max()\n",
        "customer_analysis['recency_days'] = (reference_date - customer_analysis['last_order_date']).dt.days\n",
        "\n",
        "# Create RFM Scores (1-5 scale)\n",
        "customer_analysis['recency_score'] = pd.qcut(customer_analysis['recency_days'], 5, labels=[5,4,3,2,1])  # Lower recency = better\n",
        "customer_analysis['frequency_score'] = pd.qcut(customer_analysis['order_frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
        "customer_analysis['monetary_score'] = pd.qcut(customer_analysis['total_monetary_value'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
        "\n",
        "# Combine into RFM segments\n",
        "customer_analysis['rfm_score'] = (\n",
        "    customer_analysis['recency_score'].astype(str) +\n",
        "    customer_analysis['frequency_score'].astype(str) +\n",
        "    customer_analysis['monetary_score'].astype(str)\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ RFM Analysis completed for {len(customer_analysis)} customers\")\n",
        "print(f\"Average orders per customer: {customer_analysis['order_frequency'].mean():.2f}\")\n",
        "print(f\"Average customer value: R$ {customer_analysis['total_monetary_value'].mean():.2f}\")\n",
        "print(f\"Average recency: {customer_analysis['recency_days'].mean():.0f} days\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXNDeVHaQueH",
        "outputId": "e81e9287-efda-4ef6-8bb8-0d13d36231c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßÆ BUILDING CUSTOMER RFM SEGMENTATION...\n",
            "‚úÖ RFM Analysis completed for 96476 customers\n",
            "Average orders per customer: 1.00\n",
            "Average customer value: R$ 137.04\n",
            "Average recency: 239 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define customer segments based on RFM\n",
        "def segment_customers(row):\n",
        "    score = row['rfm_score']\n",
        "    r, f, m = int(score[0]), int(score[1]), int(score[2])\n",
        "\n",
        "    if r >= 4 and f >= 4 and m >= 4:\n",
        "        return 'Champions'\n",
        "    elif r >= 3 and f >= 3 and m >= 3:\n",
        "        return 'Loyal Customers'\n",
        "    elif r >= 4 and f <= 2:\n",
        "        return 'New Customers'\n",
        "    elif r <= 2 and f >= 3:\n",
        "        return 'At Risk'\n",
        "    elif r <= 2 and f <= 2:\n",
        "        return 'Cannot Lose Them'\n",
        "    elif f >= 4:\n",
        "        return 'Potential Loyalists'\n",
        "    else:\n",
        "        return 'Others'\n",
        "\n",
        "customer_analysis['customer_segment'] = customer_analysis.apply(segment_customers, axis=1)\n",
        "\n",
        "# Segment analysis\n",
        "segment_summary = customer_analysis.groupby('customer_segment').agg({\n",
        "    'customer_id': 'count',\n",
        "    'total_monetary_value': ['mean', 'sum'],\n",
        "    'order_frequency': 'mean',\n",
        "    'recency_days': 'mean',\n",
        "    'avg_delivery_days': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "segment_summary.columns = ['customer_count', 'avg_clv', 'total_revenue', 'avg_orders', 'avg_recency', 'avg_delivery']\n",
        "segment_summary['revenue_percent'] = (segment_summary['total_revenue'] / segment_summary['total_revenue'].sum() * 100).round(1)\n",
        "\n",
        "print(\"üéØ CUSTOMER SEGMENTATION RESULTS:\")\n",
        "print(segment_summary.sort_values('total_revenue', ascending=False))\n",
        "\n",
        "print(f\"\\nüíé TOP INSIGHTS:\")\n",
        "top_segment = segment_summary.sort_values('total_revenue', ascending=False).index[0]\n",
        "print(f\"Most valuable segment: {top_segment}\")\n",
        "print(f\"Champions make up: {segment_summary.loc['Champions', 'revenue_percent'] if 'Champions' in segment_summary.index else 0}% of revenue\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_6smhneRBxH",
        "outputId": "a517e90f-770b-49e8-9c3e-02b7c0a271e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ CUSTOMER SEGMENTATION RESULTS:\n",
            "                     customer_count  avg_clv  total_revenue  avg_orders  avg_recency  avg_delivery  revenue_percent\n",
            "customer_segment                                                                                                   \n",
            "At Risk                       23247   138.63     3222698.39         1.0       396.36         12.79             24.4\n",
            "Loyal Customers               14867   174.54     2594953.72         1.0       153.31         13.57             19.6\n",
            "New Customers                 15603   137.80     2150086.74         1.0        91.38         10.86             16.3\n",
            "Cannot Lose Them              15306   137.61     2106241.96         1.0       395.93         12.75             15.9\n",
            "Champions                      6346   261.23     1657762.11         1.0        92.69         11.89             12.5\n",
            "Others                        12172    94.25     1147218.67         1.0       189.72         13.93              8.7\n",
            "Potential Loyalists            8935    38.27      341933.52         1.0       133.81         11.53              2.6\n",
            "\n",
            "üíé TOP INSIGHTS:\n",
            "Most valuable segment: At Risk\n",
            "Champions make up: 12.5% of revenue\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly sales trends\n",
        "monthly_sales = df_final.groupby(['purchase_year', 'purchase_month']).agg({\n",
        "    'order_id': 'count',\n",
        "    'total_price': 'sum',\n",
        "    'delivery_time_days': 'mean',\n",
        "    'is_late': 'mean'\n",
        "}).round(2)\n",
        "\n",
        "monthly_sales.columns = ['order_count', 'total_revenue', 'avg_delivery_days', 'late_rate']\n",
        "monthly_sales['avg_order_value'] = (monthly_sales['total_revenue'] / monthly_sales['order_count']).round(2)\n",
        "\n",
        "print(\"üìà MONTHLY SALES TRENDS:\")\n",
        "print(monthly_sales.tail(12))  # Last 12 months\n",
        "\n",
        "# Seasonal analysis\n",
        "seasonal_analysis = df_final.groupby('purchase_month').agg({\n",
        "    'order_id': 'count',\n",
        "    'total_price': 'sum',\n",
        "    'is_late': 'mean'\n",
        "}).round(2)\n",
        "seasonal_analysis.columns = ['avg_monthly_orders', 'avg_monthly_revenue', 'avg_late_rate']\n",
        "\n",
        "print(f\"\\nüóìÔ∏è SEASONAL PATTERNS:\")\n",
        "print(\"Month | Orders | Revenue | Late Rate\")\n",
        "for month, row in seasonal_analysis.iterrows():\n",
        "    month_name = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'][month-1]\n",
        "    print(f\"{month_name:>5} | {row['avg_monthly_orders']:>6.0f} | R${row['avg_monthly_revenue']:>8.0f} | {row['avg_late_rate']:>7.1%}\")\n",
        "\n",
        "# Growth analysis\n",
        "print(f\"\\nüìä BUSINESS GROWTH:\")\n",
        "yearly_growth = df_final.groupby('purchase_year')['total_price'].sum()\n",
        "if len(yearly_growth) > 1:\n",
        "    growth_rate = ((yearly_growth.iloc[-1] / yearly_growth.iloc[0]) ** (1/(len(yearly_growth)-1)) - 1) * 100\n",
        "    print(f\"Annual revenue growth rate: {growth_rate:.1f}%\")\n",
        "    print(\"Yearly revenue:\", yearly_growth.to_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fucRvwcRDg_",
        "outputId": "926e559d-faaa-4a0d-812f-c36ea8ac6174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà MONTHLY SALES TRENDS:\n",
            "                              order_count  total_revenue  avg_delivery_days  late_rate  avg_order_value\n",
            "purchase_year purchase_month                                                                           \n",
            "2017          9                      4150      607399.67              11.85       0.05           146.36\n",
            "              10                     4478      648247.65              11.86       0.05           144.76\n",
            "              11                     7288      987648.07              15.16       0.14           135.52\n",
            "              12                     5513      726033.19              15.39       0.08           131.69\n",
            "2018          1                      7069      924645.00              14.08       0.07           130.80\n",
            "              2                      6556      826467.12              16.95       0.16           126.06\n",
            "              3                      7003      953356.25              16.30       0.21           136.14\n",
            "              4                      6798      973534.09              11.50       0.05           143.21\n",
            "              5                      6749      977544.69              11.42       0.08           144.84\n",
            "              6                      6096      855591.97               9.24       0.01           140.35\n",
            "              7                      6156      867486.47               8.96       0.04           140.92\n",
            "              8                      6351      838576.64               7.73       0.10           132.04\n",
            "\n",
            "üóìÔ∏è SEASONAL PATTERNS:\n",
            "Month | Orders | Revenue | Late Rate\n",
            "  Jan |   7819 | R$ 1036443 |    6.0%\n",
            "  Feb |   8209 | R$ 1060691 |   13.0%\n",
            "  Mar |   9549 | R$ 1312555 |   17.0%\n",
            "  Apr |   9101 | R$ 1314204 |    6.0%\n",
            "  May |  10294 | R$ 1466704 |    7.0%\n",
            "  Jun |   9231 | R$ 1277515 |    2.0%\n",
            "  Jul |  10028 | R$ 1349091 |    4.0%\n",
            "  Aug |  10544 | R$ 1393276 |    8.0%\n",
            "  Sep |   4151 | R$  607535 |    5.0%\n",
            "  Oct |   4748 | R$  689189 |    5.0%\n",
            "  Nov |   7288 | R$  987648 |   14.0%\n",
            "  Dec |   5514 | R$  726044 |    8.0%\n",
            "\n",
            "üìä BUSINESS GROWTH:\n",
            "Annual revenue growth rate: 1225.4%\n",
            "Yearly revenue: {2016: 41087.17, 2017: 5962605.71, 2018: 7217202.23}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for ML modeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Create modeling dataset\n",
        "model_data = df_final[[\n",
        "    'delivery_time_days', 'same_state', 'n_items', 'total_price', 'total_freight',\n",
        "    'purchase_month', 'purchase_dow', 'customer_state', 'seller_state'\n",
        "]].copy()\n",
        "\n",
        "# Handle missing values\n",
        "model_data = model_data.dropna()\n",
        "\n",
        "# Encode categorical variables\n",
        "le_customer_state = LabelEncoder()\n",
        "le_seller_state = LabelEncoder()\n",
        "\n",
        "model_data['customer_state_encoded'] = le_customer_state.fit_transform(model_data['customer_state'])\n",
        "model_data['seller_state_encoded'] = le_seller_state.fit_transform(model_data['seller_state'])\n",
        "\n",
        "# Feature set\n",
        "feature_cols = ['same_state', 'n_items', 'total_price', 'total_freight',\n",
        "                'purchase_month', 'purchase_dow', 'customer_state_encoded', 'seller_state_encoded']\n",
        "\n",
        "X = model_data[feature_cols]\n",
        "y = model_data['delivery_time_days']\n",
        "\n",
        "# Time-based split (as you did) - last 20% chronologically\n",
        "split_date = df_final['order_purchase_timestamp'].quantile(0.8)\n",
        "train_mask = df_final.loc[model_data.index, 'order_purchase_timestamp'] <= split_date\n",
        "\n",
        "X_train, X_test = X[train_mask], X[~train_mask]\n",
        "y_train, y_test = y[train_mask], y[~train_mask]\n",
        "\n",
        "print(f\"‚úÖ Data prepared for modeling\")\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"Features: {feature_cols}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-v98lpKRDe1",
        "outputId": "bf05c9cf-25f7-4c5a-d4d7-3d8651b4d6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Data prepared for modeling\n",
            "Training set: 77181 samples\n",
            "Test set: 19295 samples\n",
            "Features: ['same_state', 'n_items', 'total_price', 'total_freight', 'purchase_month', 'purchase_dow', 'customer_state_encoded', 'seller_state_encoded']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Train models\n",
        "models = {}\n",
        "\n",
        "# Random Forest baseline\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "models['RandomForest'] = rf_model\n",
        "\n",
        "# Histogram Gradient Boosting (your best performer)\n",
        "hgb_model = HistGradientBoostingRegressor(random_state=42)\n",
        "hgb_model.fit(X_train, y_train)\n",
        "models['HistGradientBoosting'] = hgb_model\n",
        "\n",
        "print(\"‚úÖ Models trained!\")\n",
        "\n",
        "# Evaluate both models\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))  # Fixed: manual sqrt\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    results[name] = {'MAE': mae, 'RMSE': rmse, 'R¬≤': r2}\n",
        "\n",
        "    print(f\"\\nüìä {name} Results:\")\n",
        "    print(f\"MAE: {mae:.3f} days\")\n",
        "    print(f\"RMSE: {rmse:.3f} days\")\n",
        "    print(f\"R¬≤: {r2:.3f}\")\n",
        "\n",
        "# Validate key insight: same_state vs cross_state predictions\n",
        "best_model = models['HistGradientBoosting']\n",
        "\n",
        "# Test same_state performance\n",
        "same_state_mask = X_test['same_state'] == 1\n",
        "cross_state_mask = X_test['same_state'] == 0\n",
        "\n",
        "same_pred = best_model.predict(X_test[same_state_mask]).mean()\n",
        "cross_pred = best_model.predict(X_test[cross_state_mask]).mean()\n",
        "\n",
        "same_actual = y_test[same_state_mask].mean()\n",
        "cross_actual = y_test[cross_state_mask].mean()\n",
        "\n",
        "print(f\"\\nüéØ SAME_STATE VALIDATION:\")\n",
        "print(f\"Same state - Actual: {same_actual:.1f}, Predicted: {same_pred:.1f}\")\n",
        "print(f\"Cross state - Actual: {cross_actual:.1f}, Predicted: {cross_pred:.1f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2iTjy8KRDcR",
        "outputId": "16d20921-d1c1-4d92-831b-e86283d0837b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Models trained!\n",
            "\n",
            "üìä RandomForest Results:\n",
            "MAE: 4.919 days\n",
            "RMSE: 6.512 days\n",
            "R¬≤: -0.218\n",
            "\n",
            "üìä HistGradientBoosting Results:\n",
            "MAE: 4.503 days\n",
            "RMSE: 5.873 days\n",
            "R¬≤: 0.009\n",
            "\n",
            "üéØ SAME_STATE VALIDATION:\n",
            "Same state - Actual: 6.0, Predicted: 7.5\n",
            "Cross state - Actual: 10.6, Predicted: 14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance analysis - HGB doesn't have feature_importances_, use RF only\n",
        "feature_names = feature_cols\n",
        "rf_importances = rf_model.feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'RF_Importance': rf_importances,\n",
        "}).sort_values('RF_Importance', ascending=False)\n",
        "\n",
        "print(\"üéØ FEATURE IMPORTANCE ANALYSIS (Random Forest):\")\n",
        "print(importance_df.round(4))\n",
        "\n",
        "# Create a simple business rule baseline for comparison\n",
        "def simple_rule_prediction(X):\n",
        "    \"\"\"Simple business rule: 8 days same state, 15 days cross state\"\"\"\n",
        "    predictions = np.where(X['same_state'] == 1, 8.0, 15.0)\n",
        "    return predictions\n",
        "\n",
        "# Test simple rule\n",
        "rule_predictions = simple_rule_prediction(X_test)\n",
        "rule_mae = mean_absolute_error(y_test, rule_predictions)\n",
        "rule_rmse = np.sqrt(mean_squared_error(y_test, rule_predictions))\n",
        "\n",
        "print(f\"\\nüìã MODEL COMPARISON:\")\n",
        "print(f\"Simple Rule - MAE: {rule_mae:.3f}, RMSE: {rule_rmse:.3f}\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name} - MAE: {metrics['MAE']:.3f}, RMSE: {metrics['RMSE']:.3f}\")\n",
        "\n",
        "# Calculate improvement\n",
        "hgb_mae = results['HistGradientBoosting']['MAE']\n",
        "improvement = ((rule_mae - hgb_mae) / rule_mae) * 100\n",
        "print(f\"\\nüöÄ ML Improvement over simple rule: {improvement:.1f}% better MAE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3I5gxUBRZGe",
        "outputId": "e286189f-2550-42c4-ddbb-2d3665dc7f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ FEATURE IMPORTANCE ANALYSIS (Random Forest):\n",
            "                  Feature  RF_Importance\n",
            "2             total_price         0.2717\n",
            "3           total_freight         0.2527\n",
            "0              same_state         0.1338\n",
            "5            purchase_dow         0.1009\n",
            "6  customer_state_encoded         0.0997\n",
            "4          purchase_month         0.0894\n",
            "7    seller_state_encoded         0.0404\n",
            "1                 n_items         0.0113\n",
            "\n",
            "üìã MODEL COMPARISON:\n",
            "Simple Rule - MAE: 5.211, RMSE: 6.521\n",
            "RandomForest - MAE: 4.919, RMSE: 6.512\n",
            "HistGradientBoosting - MAE: 4.503, RMSE: 5.873\n",
            "\n",
            "üöÄ ML Improvement over simple rule: 13.6% better MAE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "# Prepare late delivery classification data\n",
        "class_data = df_final[['is_late'] + feature_cols[:-2] + ['customer_state', 'seller_state']].copy()\n",
        "class_data = class_data.dropna()\n",
        "\n",
        "# Encode states for classifier\n",
        "class_data['customer_state_encoded'] = le_customer_state.transform(class_data['customer_state'])\n",
        "class_data['seller_state_encoded'] = le_seller_state.transform(class_data['seller_state'])\n",
        "\n",
        "X_class = class_data[feature_cols]\n",
        "y_class = class_data['is_late'].astype(int)\n",
        "\n",
        "# Same time-based split\n",
        "class_train_mask = df_final.loc[class_data.index, 'order_purchase_timestamp'] <= split_date\n",
        "X_class_train, X_class_test = X_class[class_train_mask], X_class[~class_train_mask]\n",
        "y_class_train, y_class_test = y_class[class_train_mask], y_class[~class_train_mask]\n",
        "\n",
        "print(f\"Classification data prepared:\")\n",
        "print(f\"Train: {len(X_class_train)}, Test: {len(X_class_test)}\")\n",
        "print(f\"Late rate in train: {y_class_train.mean():.1%}\")\n",
        "print(f\"Late rate in test: {y_class_test.mean():.1%}\")\n",
        "\n",
        "# Train classifier with balanced class weights\n",
        "late_classifier = HistGradientBoostingClassifier(\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # Handle 8% imbalance\n",
        ")\n",
        "\n",
        "late_classifier.fit(X_class_train, y_class_train)\n",
        "print(\"‚úÖ Late delivery classifier trained!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z01uOhleSKcE",
        "outputId": "c5a64a7f-de24-4f39-de4b-0c42d4a0491d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification data prepared:\n",
            "Train: 77181, Test: 19295\n",
            "Late rate in train: 8.8%\n",
            "Late rate in test: 5.3%\n",
            "‚úÖ Late delivery classifier trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions and probabilities\n",
        "y_class_pred = late_classifier.predict(X_class_test)\n",
        "y_class_proba = late_classifier.predict_proba(X_class_test)[:, 1]\n",
        "\n",
        "# Evaluation\n",
        "roc_auc = roc_auc_score(y_class_test, y_class_proba)\n",
        "print(f\"üéØ LATE DELIVERY CLASSIFIER RESULTS:\")\n",
        "print(f\"ROC AUC: {roc_auc:.3f}\")\n",
        "print(f\"Late delivery rate in test: {y_class_test.mean():.1%}\")\n",
        "\n",
        "print(f\"\\nClassification Report:\")\n",
        "print(classification_report(y_class_test, y_class_pred))\n",
        "\n",
        "# Test different thresholds (as you did)\n",
        "thresholds = [0.2, 0.3, 0.5]\n",
        "print(f\"\\nüìä THRESHOLD ANALYSIS:\")\n",
        "print(\"Threshold | Precision | Recall   | Use Case\")\n",
        "print(\"-\" * 45)\n",
        "for threshold in thresholds:\n",
        "    pred_thresh = (y_class_proba >= threshold).astype(int)\n",
        "\n",
        "    precision = precision_score(y_class_test, pred_thresh, zero_division=0)\n",
        "    recall = recall_score(y_class_test, pred_thresh, zero_division=0)\n",
        "\n",
        "    if threshold == 0.2:\n",
        "        use_case = \"Catch All (Many alerts)\"\n",
        "    elif threshold == 0.3:\n",
        "        use_case = \"Balanced Operations\"\n",
        "    else:\n",
        "        use_case = \"High Confidence Only\"\n",
        "\n",
        "    print(f\"{threshold:>9} | {precision:>9.3f} | {recall:>8.3f} | {use_case}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3SeyuhWRiiB",
        "outputId": "9e48213e-0ca0-42e2-e55d-32ff782c7b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ LATE DELIVERY CLASSIFIER RESULTS:\n",
            "ROC AUC: 0.526\n",
            "Late delivery rate in test: 5.3%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95     18274\n",
            "           1       0.05      0.05      0.05      1021\n",
            "\n",
            "    accuracy                           0.90     19295\n",
            "   macro avg       0.50      0.50      0.50     19295\n",
            "weighted avg       0.90      0.90      0.90     19295\n",
            "\n",
            "\n",
            "üìä THRESHOLD ANALYSIS:\n",
            "Threshold | Precision | Recall   | Use Case\n",
            "---------------------------------------------\n",
            "      0.2 |     0.057 |    0.796 | Catch All (Many alerts)\n",
            "      0.3 |     0.054 |    0.358 | Balanced Operations\n",
            "      0.5 |     0.052 |    0.049 | High Confidence Only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all trained models and encoders for Streamlit app\n",
        "import joblib\n",
        "\n",
        "model_artifacts = {\n",
        "    'delivery_model': best_model,  # HistGradientBoosting regressor\n",
        "    'late_classifier': late_classifier,\n",
        "    'label_encoders': {\n",
        "        'customer_state': le_customer_state,\n",
        "        'seller_state': le_seller_state\n",
        "    },\n",
        "    'feature_columns': feature_cols,\n",
        "    'customer_segments': customer_analysis,\n",
        "    'monthly_sales': monthly_sales,\n",
        "    'seasonal_analysis': seasonal_analysis\n",
        "}\n",
        "\n",
        "# Save to file (we'll use this in Streamlit)\n",
        "joblib.dump(model_artifacts, '/content/olist_model_artifacts.pkl')\n",
        "\n",
        "print(\"‚úÖ All models and data saved!\")\n",
        "print(\"\\nüéØ MODEL PERFORMANCE SUMMARY:\")\n",
        "print(f\"Delivery Prediction MAE: {hgb_mae:.2f} days\")\n",
        "print(f\"Late Classification AUC: {roc_auc:.3f}\")\n",
        "print(f\"Customer Segments: {len(customer_analysis.groupby('customer_segment'))} types identified\")\n",
        "print(f\"Revenue Growth Rate: {growth_rate:.1f}% annually\")\n",
        "\n",
        "# Quick preview of what we'll showcase in Streamlit\n",
        "print(f\"\\nüì± STREAMLIT APP FEATURES READY:\")\n",
        "print(\"‚úÖ 1. Delivery Time Prediction\")\n",
        "print(\"‚úÖ 2. Late Delivery Risk Assessment\")\n",
        "print(\"‚úÖ 3. Customer Segmentation Dashboard\")\n",
        "print(\"‚úÖ 4. Sales Analytics & Trends\")\n",
        "print(\"‚úÖ 5. Business Intelligence Insights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM-jRx2TSWeG",
        "outputId": "d4a8b088-2a9e-4bbd-b1e8-9dfa2f13ab1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All models and data saved!\n",
            "\n",
            "üéØ MODEL PERFORMANCE SUMMARY:\n",
            "Delivery Prediction MAE: 4.50 days\n",
            "Late Classification AUC: 0.526\n",
            "Customer Segments: 7 types identified\n",
            "Revenue Growth Rate: 1225.4% annually\n",
            "\n",
            "üì± STREAMLIT APP FEATURES READY:\n",
            "‚úÖ 1. Delivery Time Prediction\n",
            "‚úÖ 2. Late Delivery Risk Assessment\n",
            "‚úÖ 3. Customer Segmentation Dashboard\n",
            "‚úÖ 4. Sales Analytics & Trends\n",
            "‚úÖ 5. Business Intelligence Insights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo predictions for Streamlit preview\n",
        "print(\"üöÄ PREDICTION DEMO:\")\n",
        "\n",
        "# Sample scenarios for demo\n",
        "demo_cases = [\n",
        "    {'same_state': 1, 'n_items': 1, 'total_price': 100, 'total_freight': 15,\n",
        "     'purchase_month': 5, 'purchase_dow': 2, 'customer_state_encoded': 20, 'seller_state_encoded': 20},\n",
        "    {'same_state': 0, 'n_items': 3, 'total_price': 500, 'total_freight': 45,\n",
        "     'purchase_month': 11, 'purchase_dow': 4, 'customer_state_encoded': 5, 'seller_state_encoded': 15},\n",
        "    {'same_state': 1, 'n_items': 1, 'total_price': 50, 'total_freight': 8,\n",
        "     'purchase_month': 12, 'purchase_dow': 6, 'customer_state_encoded': 10, 'seller_state_encoded': 10}\n",
        "]\n",
        "\n",
        "for i, case in enumerate(demo_cases, 1):\n",
        "    # Convert to DataFrame for prediction\n",
        "    case_df = pd.DataFrame([case])\n",
        "\n",
        "    # Delivery prediction\n",
        "    delivery_pred = best_model.predict(case_df)[0]\n",
        "\n",
        "    # Late risk prediction\n",
        "    late_prob = late_classifier.predict_proba(case_df)[0][1]\n",
        "\n",
        "    # Scenario description\n",
        "    scenario = \"Same State\" if case['same_state'] else \"Cross State\"\n",
        "    scenario += f\", {case['n_items']} items, R${case['total_price']}\"\n",
        "\n",
        "    print(f\"\\nScenario {i}: {scenario}\")\n",
        "    print(f\"  Predicted delivery: {delivery_pred:.1f} days\")\n",
        "    print(f\"  Late risk: {late_prob:.1%}\")\n",
        "    print(f\"  Risk level: {'üî¥ HIGH' if late_prob > 0.3 else 'üü° MEDIUM' if late_prob > 0.15 else 'üü¢ LOW'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RodUInm3SYTH",
        "outputId": "02951515-0113-4c62-d045-73c153f597e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ PREDICTION DEMO:\n",
            "\n",
            "Scenario 1: Same State, 1 items, R$100\n",
            "  Predicted delivery: 9.4 days\n",
            "  Late risk: 22.4%\n",
            "  Risk level: üü° MEDIUM\n",
            "\n",
            "Scenario 2: Cross State, 3 items, R$500\n",
            "  Predicted delivery: 20.4 days\n",
            "  Late risk: 62.5%\n",
            "  Risk level: üî¥ HIGH\n",
            "\n",
            "Scenario 3: Same State, 1 items, R$50\n",
            "  Predicted delivery: 5.5 days\n",
            "  Late risk: 6.0%\n",
            "  Risk level: üü¢ LOW\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab - Download the trained models\n",
        "from google.colab import files\n",
        "files.download('/content/olist_model_artifacts.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "0309RdKKSZ81",
        "outputId": "389b9c53-50aa-44a1-b281-ee5463a4252f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_747d18ac-e50b-43f6-8308-c670e0502def\", \"olist_model_artifacts.pkl\", 9043370)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ZktVqgTSxcg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}